% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rget.R
\name{bb_rget}
\alias{bb_rget}
\title{A recursive download utility}
\usage{
bb_rget(url, level = 0, wait = 0, accept_follow = c("(/|\\\\.html?)$"),
  reject_follow = character(),
  accept_download = c("\\\\.(asc|csv|nc|bin|txt|gz|bz|bz2|Z|zip|kmz|kml)$"),
  reject_download = character(), user, password, clobber = 1,
  no_check_certificate = FALSE, verbose = FALSE, show_progress = verbose,
  debug = FALSE, dry_run = FALSE, stop_on_download_error = FALSE)
}
\arguments{
\item{url}{string: the URL to retrieve}

\item{level}{integer >=0: recursively download to this maximum depth level. Specify 0 for no recursion}

\item{wait}{numeric >=0: wait this number of seconds between successive retrievals. This option may help with servers that block multiple successive requests, by introducing a delay between requests}

\item{accept_follow}{character: character vector with one or more entries. Each entry specifies a regular expression that is applied to the complete URL. URLs matching all entries will be followed during the spidering process. Note that the first URL (provided via the \code{url} parameter) will always be visited, unless it matches the download criteria}

\item{reject_follow}{character: as for \code{accept_follow}, but specifying URL regular expressions to reject}

\item{accept_download}{character: character vector with one or more entries. Each entry specifies a regular expression that is applied to the complete URL. Matching URLs will be accepted for download}

\item{reject_download}{character: as for \code{accept_regex}, but specifying URL regular expressions to reject}

\item{user}{string: username used to authenticate to the remote server}

\item{password}{string: password used to authenticate to the remote server}

\item{clobber}{numeric: 0=do not overwrite existing files, 1=overwrite if the remote file is newer than the local copy, 2=always overwrite existing files}

\item{no_check_certificate}{logical: if \code{TRUE}, don't check the server certificate against the available certificate authorities. Also don't require the URL host name to match the common name presented by the certificate. This option might be useful if trying to download files from a server with an expired certificate, but it is clearly a security risk and so should be used with caution}

\item{verbose}{logical: print trace output?}

\item{show_progress}{logical: if \code{TRUE}, show download progress}

\item{debug}{logical: if \code{TRUE}, will print additional debugging information. If bb_rget is not behaving as expected, try setting this to \code{TRUE}}

\item{dry_run}{logical: if \code{TRUE}, spider the remote site and work out which files would be downloaded, but don't download them}

\item{stop_on_download_error}{logical: if \code{TRUE}, the download process will stop if any file download fails. If \code{FALSE}, the process will issue a warning and continue to the next file to download}
}
\value{
a list with components 'ok' (TRUE/FALSE), 'files', and 'message' (error or other messages)
}
\description{
This function provides similar, but simplified, functionality to the the command-line \code{wget} utility. It is based on the \code{rvest} package.
}
\details{
NOTE: this is still highly experimental.
}
